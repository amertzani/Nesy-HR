{
  "per_query_metrics": [
    {
      "query_id": 1,
      "query": "What is the distribution of performance scores by department?",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 4.99,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 2,
      "query": "How do performance scores vary across departments?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 8.62,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 3,
      "query": "Which department has the highest average performance score?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 9.94,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 4,
      "query": "Show me performance metrics by department",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 14.15,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 5,
      "query": "What is the average special projects count by department?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 10.28,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 6,
      "query": "How do special projects vary across departments?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 12.04,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 7,
      "query": "Which department has the highest average special projects count?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 11.29,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 8,
      "query": "Show me special projects distribution by department",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 12.41,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 9,
      "query": "What is the team-level engagement by manager?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 16.55,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 10,
      "query": "How does engagement vary by manager?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 13.43,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 11,
      "query": "Which manager has the highest team engagement?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 13.42,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 12,
      "query": "What is the average salary by department?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 14.51,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 13,
      "query": "How does salary distribution vary across departments?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 19.33,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 14,
      "query": "Which department has the highest average salary?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 14.89,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 15,
      "query": "How does performance vary by recruitment source?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 16.08,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 16,
      "query": "Which recruitment sources have the employees with highest performance score?",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 22.56,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.0,
      "hallucination_rate": 1.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 17,
      "query": "What is the performance distribution by recruitment source?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 17.71,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 18,
      "query": "Identify employees with high performance, low engagement and many special projects",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.6666666666666667,
      "hallucination_rate": 0.3333333333333333,
      "evidence_count": 0,
      "gold_facts_count": 1
    },
    {
      "query_id": 19,
      "query": "Find employees with high performance, low engagement and low satisfaction",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.75,
      "hallucination_rate": 0.25,
      "evidence_count": 0,
      "gold_facts_count": 1
    },
    {
      "query_id": 20,
      "query": "Find employees with high performance, low engagement and low satisfaction and many special projects",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.5,
      "hallucination_rate": 0.5,
      "evidence_count": 0,
      "gold_facts_count": 1
    },
    {
      "query_id": 21,
      "query": "Find employees with low engagement and low satisfaction and many special projects and many absences",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.5,
      "hallucination_rate": 0.5,
      "evidence_count": 0,
      "gold_facts_count": 1
    },
    {
      "query_id": 22,
      "query": "Which departments have high salaries but low performance?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 17.83,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 23,
      "query": "Analyze the relationship between salary, performance, and department",
      "scenario_type": "operational",
      "k": 2,
      "correct": false,
      "response_time": 22.52,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 0.0,
      "hallucination_rate": 1.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 24,
      "query": "Identify departments with low salary and high performance",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 19.89,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 0.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 0,
      "gold_facts_count": 0
    },
    {
      "query_id": 25,
      "query": "Retrieve facts related with employee Becker, Scott",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.2,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 26,
      "query": "Show me all facts about employee Becker, Scott",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.2,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 27,
      "query": "What information do we have about employee Becker, Scott?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 28,
      "query": "Give me facts about the employee with the highest salary",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 29,
      "query": "Retrieve facts about the employee who has the highest salary",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 30,
      "query": "Show me information about the highest paid employee",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.01,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 31,
      "query": "Give me facts about the employee with the lowest performance",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 4.77,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 1
    },
    {
      "query_id": 32,
      "query": "Retrieve facts about the employee who has the lowest performance score",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 6.96,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 1
    },
    {
      "query_id": 33,
      "query": "Show me information about the employee with worst performance",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 5.29,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 1
    },
    {
      "query_id": 34,
      "query": "Show me facts about employees in IT/IS department",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.22,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 25,
      "gold_facts_count": 1
    },
    {
      "query_id": 35,
      "query": "What facts are available about salary information?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 36,
      "query": "Retrieve facts related to performance scores",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 37,
      "query": "Find facts about engagement by manager",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 38,
      "query": "Search for facts containing 'department' and 'salary'",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 21.77,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 39,
      "query": "Find facts about 'performance' and 'manager'",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 40,
      "query": "Retrieve facts with keywords 'engagement' and 'team'",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 0.0,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 41,
      "query": "What facts are stored about IT/IS department?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.24,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 25,
      "gold_facts_count": 1
    },
    {
      "query_id": 42,
      "query": "Show me all facts related to Production department",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.34,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 1,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 23,
      "gold_facts_count": 1
    },
    {
      "query_id": 43,
      "query": "Retrieve facts about Sales department",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.99,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 44,
      "query": "Show me all facts about employee Barbossa, Hector",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.78,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 45,
      "query": "What facts are stored about employee Becker, Scott?",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 1.92,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    },
    {
      "query_id": 46,
      "query": "Retrieve all information about employee Bacong, Alejandro",
      "scenario_type": "operational",
      "k": 2,
      "correct": true,
      "response_time": 2.29,
      "fact_retrieval_canonical": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "fact_retrieval_raw": {
        "precision": 0.0,
        "recall": 1.0,
        "f1": 0.0,
        "retrieved_count": 0,
        "gold_count": 0,
        "intersection_count": 0
      },
      "traceability_completeness": 1.0,
      "hallucination_resistance": 1.0,
      "hallucination_rate": 0.0,
      "evidence_count": 15,
      "gold_facts_count": 0
    }
  ],
  "aggregated_metrics": {
    "operational": {
      "f1": {
        "mean": 0.0,
        "ci_lower": 0.0,
        "ci_upper": 0.0,
        "std": 0.0,
        "n": 46
      },
      "precision": {
        "mean": 0.0,
        "ci_lower": 0.0,
        "ci_upper": 0.0,
        "std": 0.0,
        "n": 46
      },
      "recall": {
        "mean": 0.782608695652174,
        "ci_lower": 0.6587664204966563,
        "ci_upper": 0.9064509708076915,
        "std": 0.41702882811414954,
        "n": 46
      },
      "traceability_completeness": {
        "mean": 0.4782608695652174,
        "ci_lower": 0.32828042627448073,
        "ci_upper": 0.6282413128559541,
        "std": 0.5050469916434667,
        "n": 46
      },
      "hallucination_resistance": {
        "mean": 0.9221014492753623,
        "ci_lower": 0.8535996927020651,
        "ci_upper": 0.9906032058486595,
        "std": 0.2306741153749717,
        "n": 46
      },
      "latency": {
        "mean": 7.510434782608695,
        "ci_lower": 5.2210072571853505,
        "ci_upper": 9.79986230803204,
        "std": 7.709461706679869,
        "n": 46
      },
      "accuracy": {
        "mean": 0.8478260869565217,
        "ci_lower": 0.7399813401547636,
        "ci_upper": 0.9556708337582799,
        "std": 0.36315844747302034,
        "n": 46
      },
      "n_queries": 46
    }
  },
  "summary": {
    "total_queries": 46,
    "grouping": "scenario_type",
    "groups": [
      "operational"
    ]
  },
  "graph_data": {
    "groups": [
      "operational"
    ],
    "metrics": {
      "f1": {
        "means": [
          0.0
        ],
        "ci_lowers": [
          0.0
        ],
        "ci_uppers": [
          0.0
        ]
      },
      "precision": {
        "means": [
          0.0
        ],
        "ci_lowers": [
          0.0
        ],
        "ci_uppers": [
          0.0
        ]
      },
      "recall": {
        "means": [
          0.782608695652174
        ],
        "ci_lowers": [
          0.6587664204966563
        ],
        "ci_uppers": [
          0.9064509708076915
        ]
      },
      "traceability_completeness": {
        "means": [
          0.4782608695652174
        ],
        "ci_lowers": [
          0.32828042627448073
        ],
        "ci_uppers": [
          0.6282413128559541
        ]
      },
      "hallucination_resistance": {
        "means": [
          0.9221014492753623
        ],
        "ci_lowers": [
          0.8535996927020651
        ],
        "ci_uppers": [
          0.9906032058486595
        ]
      },
      "latency": {
        "means": [
          7.510434782608695
        ],
        "ci_lowers": [
          5.2210072571853505
        ],
        "ci_uppers": [
          9.79986230803204
        ]
      },
      "accuracy": {
        "means": [
          0.8478260869565217
        ],
        "ci_lowers": [
          0.7399813401547636
        ],
        "ci_uppers": [
          0.9556708337582799
        ]
      }
    }
  }
}